# Aula dia 31 de Agosto

## Gradiente Conjugado

Seja $Ax = b$ um sistema linear, onde $A \in \mathbb{R}^{n \times n}$ (simétria definida positiva) com $n$ muito grande.

A ideia é a achar uma sequência de vetores $x^0, x^1, \dots, x^k$ tal que $x^k \rightarrow x^*$, onde $x^*$ é a solução do sistema.

**Relembrando conceitos de álgebra linear:**

*Propriedades do produto interno:*

$\langle ., . \rangle: E \times E \rightarrow \mathbb{R}$

- $\langle x, y \rangle = \langle y, x \rangle$
- $\langle x, y + z \rangle = \langle x, y \rangle + \langle x, z \rangle$
- $\langle \alpha x, y \rangle = \alpha \langle x, y \rangle$
- $\langle x, x \rangle \geq 0$ e $\langle x, x \rangle = 0 \Leftrightarrow x = 0$

*Gram-Schmidt*

$\{u_0, u_1, \dots, u_{n-1}\}$ base ortonormal de E

$\{d_0, d_1, \dots, d_{n-1}\}$ base ortonormal de E

$d_0 = u_0$

$d_1 = u_1 - \frac{\langle u_1, d_0 \rangle}{\langle d_0, d_0 \rangle}d_0$

$d_2 = u_2 - \frac{\langle u_2, d_0 \rangle}{\langle d_0, d_0 \rangle}d_0 - \frac{\langle u_2, d_1 \rangle}{\langle d_1, d_1 \rangle}d_1$

$\vdots$

$d_{i} = u_{i} - \sum_{j=0}^{i-1} \frac{\langle u_{i}, d_{j} \rangle}{\langle d_{j}, d_{j} \rangle}d_{j}$

**Definimos:** $\langle x, y \rangle = x^T A y$

$d_i, d_j$ são ortogonais quando $d_i^T A d_j = 0$

$x^* = \alpha_0 d_0 + \alpha_1 d_1 + \dots + \alpha_{n-1} d_{n-1}$

Como calcular $\alpha_i$?

$d_{k}^T Ax^* = d_{k}^T A (\alpha_0 d_0 + \alpha_1 d_1 + \dots + \alpha_{n-1} d_{n-1}) \\
d_{k}^Tb = \alpha_k d_{k}^T A d_k \\
\alpha_k = \frac{d_{k}^Tb}{d_{k}^T A d_k}$

Resumindo:

- Pega uma base $u_0, u_1, \dots, u_{n-1}$ de E
- Aplica Gram-Schmidt
- Calcula $\alpha_i = \frac{d_{k}^Tb}{d_{k}^T A d_k}$
- Encotra $x^* = \alpha_0 d_0 + \alpha_1 d_1 + \dots + \alpha_{n-1} d_{n-1}$

*Observação:* É um processo custoso.

*Precisamos modificar esse método para que ele seja menos custoso.*

$x^* = \alpha_0 d_0 + \alpha_1 d_1 + \dots + \alpha_{n-1} d_{n-1}$

$d_{k}^T Ax^* = d_{k}^T A (x^{(0)} + \alpha_0 d_0 + \alpha_1 d_1 + \dots + \alpha_{n-1} d_{n-1}) \\
d_{k}^Tb = d_{k}^T A x^{(0)} + \alpha_k d_{k}^T A d_k \\
\alpha_k = \frac{d_{k}^Tb - d_{k}^T A x^{(0)}}{d_{k}^T A d_k}$

**Definimos:** 

- $x^k = x^{(0)} + \alpha_0 d_0 + \alpha_1 d_1 + \dots + \alpha_{k-1} d_{k-1}$

- Resíduo: $r_k = b - Ax^k$

Note que: $x^k = x^{k-1} + \alpha_{k-1} d_{k-1}$

$a_k = \frac{d_{k}^T (b - A(x^0 + \alpha_0 d_0 + \alpha_1 d_1 + \dots + \alpha_{k-1} d_{k-1}))}{d_{k}^T A d_k} = \frac{d_{k}^T r_{k}}{d_{k}^T A d_k}$

*Pseudo-código:*

```
input {d_0, d_1, ..., d_{n-1}} # A-ortogonais

    r_0 = b - A*d_0, if r_0 = 0 # stop (x* = x_0)
    a_0 = (d_0' * r_0)/(d_0' * A * d_0)
    x_1 = x_0 + a_0*d_0
    r_1 = b - A*x_1, if r_1 = 0 # stop (x* = x_1)
    \dots 
```

*Outro algoritmo:*

```
input {u_0, u_1, ..., u_{n-1}}, x_0, A, b
    d_0 = u_0
    r_0 = b - A*d_0
    if r_0 = 0 then x* = x_0, stop

    for k=0:n-1
        d_k = (d_k' * r_k)/(d_k' * A * d_k) 
        x_{k+1} = x_k + a_k*d_k
        r_{k+1} = r_k - A*a_k*d_k, if r_{k+1} = 0 then x* = x_{k+1}, stop
        d_{k+1} = u_{k+1} - (u_{k+1}'*A*d_0)/(d_0'*A*d_0)*d_0 - ... - (u_{k+1}'*A*d_k)/(d_k'*A*d_k)*d_k
end
```

## O que veremos na próxima aula?

### Interpolação polinomial

Consiste basicamente em encontrar um polinômio que passe por um conjunto de pontos.

Utilidades:
- Aproximar integrais

Supondo que temos $(x_1, y_1), (x_2, y_2), \dots, (x_n, y_n)$ no plano cartesiano.

Queremos encontrar um polinômio $p(x)$ tal que $p(x_i) = y_i$, $i = 1, 2, \dots, n$.

Quando temos:
- 2 pontos, temos uma reta
- 3 pontos, temos uma parábola
- 4 pontos, temos um polinômio de grau 3
- $\vdots$
- $n$ pontos, temos um polinômio de grau $n-1$

*Como construir esse polinômio?*

$p(x) = a_0 + a_1x + a_2x^2 + a_3x^3$

$\begin{cases}
p(x_1) = y_1 \\
p(x_2) = y_2 \\
p(x_3) = y_3
p(x_4) = y_4
\end{cases}$

Sistema:

$\begin{bmatrix}
x_1^3 & x_1^2 & x_1 & 1 \\
x_2^3 & x_2^2 & x_2 & 1 \\
x_3^3 & x_3^2 & x_3 & 1
\end{bmatrix} \begin{bmatrix}
a_3 \\
a_2 \\
a_1 \\
a_0
\end{bmatrix} = \begin{bmatrix}
y_1 \\
y_2 \\
y_3
\end{bmatrix}$

*Lagrange*

$p(x) = \frac{(x-x_4)(x-x_2)(x-x_3)}{(x_1-x_2) (x_1-x_3) (x_1-x_4)} y_1 + \frac{(x-x_1)(x-x_3)(x-x_4)}{(x_2-x_1) (x_2-x_3) (x_2-x_4)} y_2 + \frac{(x-x_1)(x-x_2)(x-x_4)}{(x_3-x_1) (x_3-x_2) (x_3-x_4)} y_3 + \frac{(x-x_1)(x-x_2)(x-x_3)}{(x_4-x_1) (x_4-x_2) (x_4-x_3)} y_4$






